# 幂等性

## 1、什么是幂等性

**接口幂等性就是用户对于同一个操作发起的一次请求或多次请求的结果是一致的。**不会因为多次点击而产生副作用；比如支付场景，用户购买了商品，支付扣款成功，但是返回结果的时候因为网络异常，此时钱已经扣除了，用户再次点击按钮，此时会第二次调用扣款，返回结果成功。这时用户查询余额发现多扣了钱，流水记录也变成了两条，这就是因为没有保证接口幂等性。

## 2、什么情况需要防止

+ 用户多次点击按钮
+ 用户页面回退再次提交
+ 微服务间的相互调用，由于网络问题，导致请求失败。【feign会触发重试机制】
+ 其他业务情况

## 3、什么情况下需要幂等

以SQL为例，有些操作是天然幂等的，如：

+ `select * from user where id=1`，无论执行多少次，都不会改变状态，是天然幂等的。
+ `update tb set col1 =1 where col2=2`，无论执行成功多少次状态都是一致的，也是幂等操作。
+ `delete from user where id=1`，多次操作，结果一致，具有幂等性。
+ `insert into user(userid,name) values(1,'a')`，如果userid为唯一主键，即重复上述业务也只会插入一条记录，具有幂等性。

而有些操作，并不具备幂等性，如：

+ `update tb1 set col1=col1+1 where col2=2`，每次执行的结果都会发生变化，不是幂等。
+ `insert into(userid, name) values(1,'a')`，如userid不是主键，就会重复插入，不是幂等的。

## 4、幂等解决方案

### 1、token机制

1. 服务端提供了发送token的接口。在分析业务的时候，将存在幂等性问题的业务提取出来；
2. 在这些业务执行前，先获取token，服务器会把token保存到redis中。
3. 然后调用业务接口请求时，把token携带过去，一般放到头部。
4. 服务器判断token是否存redis中，存表示第一次请求，然后删除token，继续执行业务。
5. 如果判断token不存在redis中，表示重复提交，直接返回重复标记个client，主要保证业务代码不重复执行。

> 隐患

1. 执行业务前删除token还是执行业务后删除token；

   1. 先删除可能导致，业务确实没有执行(由于异常情况，没执行成功)，重试还带上之前的token，由于防重设计导致，请求还是不能执行。
   2. 后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除token，继续重试，导致业务执行两遍。
   3. 最好还是设计为先删除token，如果业务执行失败，重新获取token再次查询就是。

2. token获取、比较和删除必须是原子性的；

   1. redis.get(token)、redis.equals、redis.del(token)如果这些操作不是原子性，就可能导致高并发下get同样的数据，判断都成功，继续业务并发执行。

   2. 可以在redis使用lua脚本完成原子性操作

      ```lua
      if redis.call('get',KEYS[1]) == ARGV[1] 
      then 
          return redis.call('del', KEYS[1]) 
      else 
          return 0 
      end
      ```

### 2、各种锁机制

#### 1、数据库悲观锁

`select *from xx where id=1 for update`

悲观锁使用时一般伴随事务一起使用，数据锁定时间可能很长，根据实际情况选用。

另外要注意的是，id字段一定是主键或者唯一索引，不然可能导致锁表的结果，处理起来很麻烦。

#### 2、数据库乐观锁

`update t_good set count=count-1,version=version+1 wehre good_id=2 and version=1`

乐观锁使用在更新场景，根据版本号，在操作数据库前先获取当前商品的version版本号，然后操作的时候带上此版本号。

第一次操作库存时，version=1，调用库存服务，version变成了2；

但是返回订单服务出现了问题，订单服务再次发起调用库存服务，当前订单服务如果给的version还是1，将不会被执行；

因为version已经变为了2，where将不再成立，不管调用几次，只会真正调用处理一次。

乐观锁适用于读多写少的情况。

#### 3、业务层分布式锁

多个机器可能同时处理同样的数据，如果多台机器定时任务同时拿到相同数据处理，这是可以加分布式锁，锁定此数据，处理完成之后释放锁。获取到锁的必须先判断数据是否已经被处理。

### 3、各种唯一约束

#### 1、数据库唯一约束

插入数据，按照唯一索引插入，如订单号，相同的订单号不可能有两条记录。

在数据库层面防止重复，这个机制就是利用了数据库的主键唯一索引的特性，解决了在insert场景时幂等性问题。

但是主键要求不是自增的主键，这样就需要业务生成全局唯一的主键。

如果在分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一张表中，要不然数据库主键约束将不起作用，因为不同数据库的表主键不相关。

#### 2、redis set 防重

很多数据需要处理，只能被处理一次，比如我们可以数据的MD5将其放入redis中的set，每次处理数据，先看这个MD5是否已经存在，存在就不处理。

### 4、防重表

使用订单号作为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且他们在同一个事务中。

这个保证重复请求时，因为去重表有唯一约束，导致插入失败，不会继续操作，保证了幂等性。

需要注意的是，去重表和业务表应该在同一个库中，保证了在同一事务，即时事务失败，也会把去重表数据回滚，保证一致性。

### 5、全局请求唯一id

调用接口是，生成唯一id，redis将数据保存到集合中（去重），存在即处理过，可以使用nginx设置每个请求的唯一id；

```nginx
proxy_set_head X-Request-Id $request_id;
```

